{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367dbcd4",
   "metadata": {},
   "source": [
    "## 0.导入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium模块用于网页自动化\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#time模块用于爬虫间的休眠，避免频繁访问\n",
    "import time\n",
    "#数据处理常用的pandas、numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a81be",
   "metadata": {},
   "source": [
    "## 1.使用selenium驱动浏览器进行网页自动化-part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20afaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "url = r'https://exam.sac.net.cn/pages/registration/sac-publicity-report.html'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "def construct_url(a):\n",
    "    return r'https://exam.sac.net.cn/pages/registration/sac-publicity-finish.html?aoiId=' + a\n",
    "\n",
    "def catch_id(a):\n",
    "    return a.get_attribute('onclick').split('(')[1][:-1]\n",
    "\n",
    "#按6下空格，确保网页滑动到最底端，页面上内容全部加载完毕\n",
    "for i in range(6):\n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "    time.sleep(1)\n",
    "\n",
    "all_companies = driver.find_elements_by_xpath('//*[@id=\"publicityOtherList\"]/tr/td[2]/a')\n",
    "all_companies_names = [a.text for a in all_companies]\n",
    "all_companies_urls = [construct_url(catch_id(a)) for a in all_companies]\n",
    "print(all_companies_urls)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30233741",
   "metadata": {},
   "source": [
    "## 2.使用pandas整理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7565443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#companies_df用来存储公司的基本信息\n",
    "companies_df = pd.DataFrame(columns=['name','url'])\n",
    "companies_df['name'] = all_companies_names\n",
    "companies_df['url'] = all_companies_urls\n",
    "companies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c9e39",
   "metadata": {},
   "source": [
    "## 3.使用selenium驱动浏览器进行网页自动化-part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysts_df用来存储分析师的基本信息\n",
    "analysts_df = pd.DataFrame(columns=['company','name','url'])\n",
    "\n",
    "count = 0\n",
    "for i in range(len(all_companies_urls)):\n",
    "    company_url = all_companies_urls[i]\n",
    "    company_name = all_companies_names[i]\n",
    "    print(company_name)\n",
    "    print(company_url)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(company_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    #要进行翻页操作，首先确定要翻多少次页\n",
    "    page_number = int(driver.find_element_by_xpath('//*[@id=\"sp_1\"]').text)\n",
    "    \n",
    "    for pn in range(page_number-1): #进行page_number次翻页\n",
    "\n",
    "        #同样的通过按空格键，跳转到页面底部，保证页面内容加载完成\n",
    "        for send_key in range(6):\n",
    "            driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "            time.sleep(1)  \n",
    "\n",
    "        analysts_urls = driver.find_elements_by_xpath('/html/body/table/tbody/tr[2]/td/table/tbody/tr[2]/td/div/div/div[3]/div[4]/div/table/tbody/tr/td[1]')\n",
    "        analysts_urls = [a.get_attribute('title') for a in analysts_urls]\n",
    "        analysts_urls = analysts_urls[1:]\n",
    "        \n",
    "        analysts_names = driver.find_elements_by_xpath('/html/body/table/tbody/tr[2]/td/table/tbody/tr[2]/td/div/div/div[3]/div[4]/div/table/tbody/tr/td[2]/a')\n",
    "        analysts_names = [a.text for a in analysts_names]\n",
    "        \n",
    "        #存储每个公司的，每个分析师的个人主页地址，存储到analysts_df中\n",
    "        for ii in range(len(analysts_names)):\n",
    "            company_name = company_name\n",
    "            name = analysts_names[ii]\n",
    "            url = analysts_urls[ii]\n",
    "            \n",
    "            analysts_df.loc[count,:] = [company_name,name,url]\n",
    "            count += 1\n",
    "        \n",
    "        #找到下一页的按钮，点击\n",
    "        next_button = driver.find_element_by_xpath('//*[@id=\"next_t\"]/span')\n",
    "        next_button.click()\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7d4a5",
   "metadata": {},
   "source": [
    "## 4.下载每位分析师的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download pics\n",
    "\n",
    "#建立pics文件夹用来存储下载的图片\n",
    "if os.path.exists('./pics') == False:\n",
    "    os.mkdir('./pics')\n",
    "    \n",
    "driver = webdriver.Chrome()\n",
    "for url in analysts_df['url']:\n",
    "    #进入每个分析师的个人主页，定位其照片元素，找到对应url\n",
    "    driver.get('https://exam.sac.net.cn/pages/registration/sac-finish-person.html?r2SS_IFjjk='+url)\n",
    "    img = driver.find_element_by_xpath('//*[@id=\"RPI_PHOTO_PATH\"]/img')\n",
    "    img_url = img.get_attribute('src')\n",
    "    \n",
    "    print(img_url)\n",
    "    \n",
    "    #使用requests模块访问并下载图片\n",
    "    r = requests.get(img_url)\n",
    "    with open('./pics/%s.png' % url, 'wb') as f:\n",
    "        f.write(r.content)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
