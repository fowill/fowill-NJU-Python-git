{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.文件整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = os.getcwd()+'/Lecture8-data'\n",
    "names = os.listdir(base_path)\n",
    "\n",
    "os.mkdir('./Lecture8-data/trans') #将修改后的文件放入tran文件夹，所以这里新建一个\n",
    "\n",
    "for name in names:\n",
    "    if name.find('.txt')!=-1: #只要我们需要的.txt文件\n",
    "        path = base_path+'/'+name\n",
    "        os.rename(path,base_path+'/trans/'+str(os.path.getctime(path))+'.txt') #新的文件名为其创建时间的时间戳\n",
    "    \n",
    "#注意 运行完后 原有文件会消失 工作时请注意好备份"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.pdf读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "with pdfplumber.open(\"./Lecture8-data/paper.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        print(page.extract_text())\n",
    "        with open('./Lecture8-data/paper_to_txt.txt','w+') as f: #把提取的结果存储到paper_to_txt文件\n",
    "            f.write(page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.使用正则表达式匹配信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = '''歪你打错了！我不是wly！重要的事情说31237938123789遍，我的手机号是13512346789，不是15600998765，\n",
    "也不是110或119或者19023456789，我的手机号是15600998765，别再打给我啦！'''\n",
    "\n",
    "#beta 1\n",
    "regex1 = re.compile(r'\\d{11}') #re.compile函数构建一个正则表达式对象\n",
    "result1 = regex1.findall(text) #调用该对象的.findall()方法，在传入的参数text中找到符合正则表达式语法的部分\n",
    "print(result1)\n",
    "\n",
    "#beta 2\n",
    "regex2 = re.compile(r'(?<=\\D)1[3578]\\d{9}(?=\\D)') #同上，注意这里正则表达式前瞻和后顾的写法，以及增加了对于手机号开头两位数的细化匹配\n",
    "result2 = regex2.findall(text)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#文件读取部分，记得使用r+模式（read模式），同a+模式（append模式）区分开\n",
    "with open('./Lecture8-data/material/经纬度提取.txt','r+') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#使用正则表达式匹配\n",
    "lats_regex = re.compile(r'\"lat\":\"\\d{2}\\.\\d{6}')\n",
    "lats = lats_regex.findall(text)\n",
    "\n",
    "print(lats)\n",
    "\n",
    "#循环去除不必要的字符\n",
    "newLats = []\n",
    "for lat in lats:\n",
    "    newLats.append(lat.replace('\"lat\":\"',''))\n",
    "    \n",
    "print(newLats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.提取摘要和关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from textrank4zh import TextRank4Keyword, TextRank4Sentence\n",
    "\n",
    "text = codecs.open('./Lecture8-data/material/摘要提取.txt', 'r', 'utf-8').read()\n",
    "tr4w = TextRank4Keyword()\n",
    "\n",
    "tr4w.analyze(text=text, lower=True, window=2)  #py3中必须是utf8编码的bytes或者str对象\n",
    "\n",
    "print( '关键词：' )\n",
    "for item in tr4w.get_keywords(20, word_min_len=1):\n",
    "    print(item.word, item.weight)\n",
    "\n",
    "print()\n",
    "print( '关键短语：' )\n",
    "for phrase in tr4w.get_keyphrases(keywords_num=20, min_occur_num= 2):\n",
    "    print(phrase)\n",
    "\n",
    "tr4s = TextRank4Sentence()\n",
    "tr4s.analyze(text=text, lower=True, source = 'all_filters')\n",
    "\n",
    "print()\n",
    "print( '摘要：' )\n",
    "for item in tr4s.get_key_sentences(num=3):\n",
    "    print(item.index, item.weight, item.sentence)  # index是语句在文本中位置，weight是权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.调用百度api进行自然语言处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aip import AipNlp\n",
    "\n",
    "#以下id仅用于测试，建议自己注册一个\n",
    "\n",
    "APP_ID = '18102862'\n",
    "API_KEY = 'igU7dumhhWws35yIMUE6wGRL'\n",
    "SECRET_KEY = 'hE9QieKEA3nYUrGIbKVbIdrmEZGsUGgS'\n",
    "\n",
    "client = AipNlp(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    "text1 = \"工程管理学院\"\n",
    "\n",
    "text2 = \"信息管理学院\"\n",
    "\n",
    "\"\"\" 调用短文本相似度 \"\"\"\n",
    "client.simnet(text1, text2);\n",
    "\n",
    "\"\"\" 带参数调用短文本相似度 \"\"\"\n",
    "client.simnet(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"苹果是一家伟大的公司\"\n",
    "\n",
    "\"\"\" 调用情感倾向分析 \"\"\"\n",
    "print(client.sentimentClassify(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
